{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VOjixh-2QtGi"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Найти или сгенерировать набор данных для бинарной классификации графов**"
      ],
      "metadata": {
        "id": "rmyyf3w5SO1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(size = 100, nodes = 30):\n",
        "    graph_list = [nx.cycle_graph(nodes) for i in range(10, size//2 + 10)]\n",
        "    graph_list.extend([nx.path_graph(nodes) for i in range(size//2 + 10, size + 10)])\n",
        "    y = [0 if i < (size//2 + 10) else 1 for i in range(size)]\n",
        "\n",
        "    return graph_list, y\n",
        "\n",
        "graph_list, y = create_dataset(500, 50)\n",
        "train_graphs, test_graphs, y_train, y_test = train_test_split(graph_list, y, test_size=0.1, stratify=y)"
      ],
      "metadata": {
        "id": "2BPTWzaZRaFn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Реализовать функцию `shortest_path_kernel(train_graphs, test_graphs)`, которая принимает тренировочный и тестовые наборы, а возвращает пару `K_train, K_test`**\n",
        "  - Опишите графы с помощью вектора из количества кратчайших путей различной длины\n",
        "  - Для вычисления длин кратчайших путей можно использовать `nx.shortest_path_length(G)`\n",
        "  - Ядровая функция для сравнения двух графов - скалярное произведение их двух векторов\n",
        "  - `K_train` - матрица из ядровых функций для сравнения тренировочных графов между собой\n",
        "  - `K_test` - матрица из ядровых функций для сравнения тестовых графов с тренировочными"
      ],
      "metadata": {
        "id": "fF5nbr3qSlTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shortest_path_kernel(train_graphs, test_graphs, nodes = 50):\n",
        "\n",
        "  # initialization\n",
        "  train_vector = np.zeros((len(train_graphs), nodes * (nodes - 1)))\n",
        "  test_vector = np.zeros((len(test_graphs), nodes * (nodes - 1)))\n",
        "\n",
        "  # train_graphs\n",
        "  for i, graph in enumerate(train_graphs):\n",
        "    idx = 0\n",
        "    # fill vector with shortest paths between each nodes\n",
        "    for u in range(graph.number_of_nodes() - 1):\n",
        "      for v in range(u + 1, graph.number_of_nodes()):\n",
        "        train_vector[i][idx] = nx.shortest_path_length(graph, u, v)\n",
        "        idx += 1\n",
        "\n",
        "  # test_graphs\n",
        "  for i, graph in enumerate(test_graphs):\n",
        "    idx = 0\n",
        "    for u in range(graph.number_of_nodes() - 1):\n",
        "      for v in range(u + 1, graph.number_of_nodes()):\n",
        "        test_vector[i][idx] = nx.shortest_path_length(graph, u, v)\n",
        "        idx += 1\n",
        "\n",
        "  # kernel functions matrixs\n",
        "  K_train = np.dot(train_vector, train_vector.T)\n",
        "  K_test = np.dot(test_vector, train_vector.T)\n",
        "  return K_train, K_test\n",
        "\n",
        "K_train, K_test = shortest_path_kernel(train_graphs, test_graphs)"
      ],
      "metadata": {
        "id": "XcYF9OwjSbCl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Используя реализованное ядро обучите модель SVC, подберите гиперпараметры, вычислите различные метрики качества**"
      ],
      "metadata": {
        "id": "UYgFU7IPWwtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tune GridSearch params\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.05, 0.1, 1, 10, 100, 1000],\n",
        "    'cache_size': [50, 100, 200],\n",
        "    'tol': [0.01, 0.001, 0.0001]\n",
        "}\n",
        "# search best params\n",
        "model = SVC(kernel ='precomputed')\n",
        "grid = GridSearchCV(model, param_grid)\n",
        "grid.fit(K_train, y_train)\n",
        "best_params = grid.best_params_\n",
        "\n",
        "print(best_params)\n",
        "\n",
        "# predict best model and compute metrics\n",
        "y_pred = grid.predict(K_test)\n",
        "\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
        "print(f'Precision: {precision_score(y_test, y_pred)}')\n",
        "print(f'Recall: {recall_score(y_test, y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poQRt0EqWzYO",
        "outputId": "4e80c107-defb-41ba-bfa6-0e2e5cd49dbb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 0.01, 'cache_size': 50, 'tol': 0.01}\n",
            "Accuracy: 0.98\n",
            "Precision: 0.96\n",
            "Recall: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Также реализовать Weisfeiler-Lehman Kernel и обучить классификатор с ним, сравнить результаты.**"
      ],
      "metadata": {
        "id": "zJYy3VOwaOFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weisfeiler_lehman_kernel(train_graphs, test_graphs, iteration=5):\n",
        "    K_train = np.zeros((len(train_graphs), len(train_graphs)))\n",
        "    K_test = np.zeros((len(test_graphs), len(train_graphs)))\n",
        "    # List with coloring results\n",
        "    train_graphs_labels = [weisfeiler_lehman_labels(G, iteration) for G in train_graphs]\n",
        "    test_graphs_labels = [weisfeiler_lehman_labels(G, iteration) for G in test_graphs]\n",
        "\n",
        "    # Calculating each cell of K_train\n",
        "    for i in range(len(train_graphs)):\n",
        "        for j in range(i, len(train_graphs)):\n",
        "            # Calculating the kernel value\n",
        "            kernel_value = weisfeiler_lehman_kernel_value(train_graphs_labels[i], train_graphs_labels[j])\n",
        "            K_train[i, j] = kernel_value\n",
        "            # Mirror the kernel values along the diagonal\n",
        "            K_train[j, i] = kernel_value\n",
        "\n",
        "    # Calculating each cell of K_test\n",
        "    for i in range(len(test_graphs)):\n",
        "        for j in range(len(train_graphs)):\n",
        "            # Calculating the kernel value\n",
        "            kernel_value = weisfeiler_lehman_kernel_value(test_graphs_labels[i], train_graphs_labels[j])\n",
        "            K_test[i, j] = kernel_value\n",
        "\n",
        "    return K_train, K_test\n",
        "\n",
        "def weisfeiler_lehman_labels(graph, iteration):\n",
        "    # Initialize all colors with the degree of the vertex\n",
        "    labels = {node: str(graph.degree(node)) for node in graph.nodes()}\n",
        "\n",
        "    for _ in range(iteration):\n",
        "        # Compute new colors based on neighbors\n",
        "        new_labels = {}\n",
        "        for node in graph.nodes():\n",
        "            neighbors = graph.neighbors(node)\n",
        "            # Node color + sorted colors of neighboring vertices\n",
        "            new_label = [labels[node]] + sorted([labels[neighbor] for neighbor in neighbors])\n",
        "            new_label = \",\".join(new_label)\n",
        "\n",
        "            # Store the new color of the vertex (using a hash to save memory)\n",
        "            new_labels[node] = str(hash(new_label))\n",
        "            # new_labels[node] = new_label\n",
        "        # Update colors\n",
        "        labels = new_labels\n",
        "    return labels\n",
        "\n",
        "def weisfeiler_lehman_kernel_value(labels_i, labels_j):\n",
        "    # Count each color in each graph\n",
        "    kernel_value = 0\n",
        "    counts_i = {}\n",
        "    counts_j = {}\n",
        "    for label in labels_i.values():\n",
        "        counts_i[label] = counts_i.get(label, 0) + 1\n",
        "    for label in labels_j.values():\n",
        "        counts_j[label] = counts_j.get(label, 0) + 1\n",
        "    # Compute the vector as the dot product of color frequencies\n",
        "    for label in set(counts_i.keys()).union(counts_j.keys()):\n",
        "        kernel_value += counts_i.get(label, 0) * counts_j.get(label, 0)\n",
        "    return kernel_value\n",
        "\n",
        "K_train_wl, K_test_wl = weisfeiler_lehman_kernel(train_graphs, test_graphs)"
      ],
      "metadata": {
        "id": "BkmKC1LmbNqs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tune GridSearch params\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.05, 0.1, 1, 10, 100, 1000],\n",
        "    'cache_size': [50, 100, 200],\n",
        "    'tol': [0.01, 0.001, 0.0001]\n",
        "}\n",
        "# search best params\n",
        "model = SVC(kernel ='precomputed')\n",
        "wl_grid = GridSearchCV(model, param_grid, refit = True)\n",
        "wl_grid.fit(K_train_wl, y_train)\n",
        "wl_best_params = wl_grid.best_params_\n",
        "\n",
        "print(wl_best_params)\n",
        "\n",
        "# predict best model and compute metrics\n",
        "y_pred_wl = wl_grid.predict(K_test_wl)\n",
        "\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred_wl)}')\n",
        "print(f'Precision: {precision_score(y_test, y_pred_wl)}')\n",
        "print(f'Recall: {recall_score(y_test, y_pred_wl)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6Q7Rc9sbSSO",
        "outputId": "c8f51de9-ad93-4dd4-f74b-06e8ae915e3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 0.01, 'cache_size': 50, 'tol': 0.01}\n",
            "Accuracy: 0.98\n",
            "Precision: 0.96\n",
            "Recall: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Выводы**:\n",
        "* Оба метода показали хорошие результаты\n",
        "* Выбор метода может зависеть от конкретных задач. Если важно избежать ложных срабатываний (например, минимизировать ложноположительные результаты), лучше использовать Shortest Path Kernel.\n",
        "* Если же важнее находить все положительные примеры, даже с возможными ложными срабатываниями, стоит предпочесть Weisfeiler-Lehman Kernel"
      ],
      "metadata": {
        "id": "Vn5YtdHhhUY6"
      }
    }
  ]
}